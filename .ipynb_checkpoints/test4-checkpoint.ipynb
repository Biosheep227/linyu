{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c102046e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from keras import callbacks\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.layers import *\n",
    "from PIL import Image\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4cdfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_activities(df_s):\n",
    "    activitiesSeq = []\n",
    "    ponentialIndex = df_s.label.ne(df_s.label.shift())\n",
    "    ii = np.where(ponentialIndex == True)[0]\n",
    "    for i_s, end in enumerate(ii):\n",
    "        if i_s > 0:\n",
    "            df_stmp = df_s[ii[i_s - 1]:end]\n",
    "            activitiesSeq.append(df_stmp)\n",
    "    return activitiesSeq\n",
    "\n",
    "def sequences_to_sentences(activity_sequences_s):\n",
    "    sentences_s = []\n",
    "    label_sentences_s = []\n",
    "    for i_s in range(len(activity_sequences_s)):\n",
    "        sentence = generate_sentence(activity_sequences_s[i_s])\n",
    "        sentences_s.append(sentence)\n",
    "        label_sentences_s.append(activity_sequences_s[i_s].label.values[0])\n",
    "    return sentences_s, label_sentences_s\n",
    "\n",
    "def generate_sentence(df2):\n",
    "    sentence = \"\"\n",
    "    sensors = df2.sensor.values\n",
    "#    values = df2.status.values\n",
    "    for i_s in range(len(sensors)):\n",
    "#        val = values[i_s]\n",
    "        if i_s == len(sensors) - 1:\n",
    "            sentence += \"{}\".format(sensors[i_s])\n",
    "        else:\n",
    "            sentence += \"{} \".format(sensors[i_s])\n",
    "    return sentence\n",
    "\n",
    "def sliding_window(sequence, win_size_s, step_s=1):\n",
    "    try:\n",
    "        iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    numOfChunks = int(((len(sequence) - win_size_s) / step_s) + 1)\n",
    "\n",
    "    if win_size_s > len(sequence):\n",
    "        yield sequence[0:len(sequence)]\n",
    "    else:\n",
    "        for i_s in range(0, numOfChunks * step_s, step_s):\n",
    "            yield sequence[i_s:i_s + win_size_s]\n",
    "\n",
    "# 定义一个函数来填充1和0.5之间的值\n",
    "def fill_between_values(col, df, col_name):\n",
    "    first_one_index = col[col == 1].index.min()\n",
    "    # 如果存在1的值，将其之前的所有值填充为0.5\n",
    "    if first_one_index is not None:\n",
    "        df.loc[:first_one_index - 1, col_name] = 0.5\n",
    "\n",
    "    start_index = None\n",
    "    previous_value = None\n",
    "    for idx, value in col.items():\n",
    "        if value == 1 or value == 0.5:\n",
    "            if start_index is not None:\n",
    "                if previous_value == 1:\n",
    "                    df.loc[start_index:idx-1, col_name] = 1\n",
    "                elif previous_value == 0.5:\n",
    "                    df.loc[start_index:idx-1, col_name] = 0.5\n",
    "                start_index = None\n",
    "            previous_value = value\n",
    "        elif start_index is None:\n",
    "            start_index = idx\n",
    "\n",
    "    return df[col_name]\n",
    "\n",
    "def count_directories(path):\n",
    "    dir_count = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # 在第一层停止，不遍历子目录\n",
    "        dir_count += len(dirs)\n",
    "        break  # 只处理顶层目录，不进入子目录\n",
    "    return dir_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f526e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1013_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(df))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('1013_clean.csv', header=None, names=[\"date\", \"time\", \"sensor\", \"status\"])\n",
    "df = df.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "print(type(df))\n",
    "print(df[:10])\n",
    "\n",
    "# 将 'sensor' 列转换为整数\n",
    "df = df[df['sensor'] != 'sensor']\n",
    "df['sensor'] = pd.to_numeric(df['sensor'])\n",
    "df['status'] = df['status'].astype(float)\n",
    "\n",
    "# 定义特殊的sensor值\n",
    "special_sensors = [100,101,102,103,104,105,106]\n",
    "\n",
    "# 对每个特殊的sensor进行处理\n",
    "for sensor in special_sensors:\n",
    "    # 新增一列，并为符合条件的行填充对应的值\n",
    "    df[sensor] = (df[\"sensor\"] == sensor).astype(int) * df[\"status\"]\n",
    "\n",
    "for col_name in df.columns[4:]:\n",
    "    df[col_name] = fill_between_values(df[col_name], df, col_name)\n",
    "print(df[:10])\n",
    "\n",
    "\n",
    "for sensor in special_sensors:\n",
    "        # 删除包含特殊sensor值的行\n",
    "    df = df[df[\"sensor\"] != sensor]\n",
    "\n",
    "print(df[:10])\n",
    "\n",
    "df['label'] = df[special_sensors].apply(tuple, axis=1)\n",
    "df.drop(columns=special_sensors, inplace=True)\n",
    "\n",
    "print(df[:10])\n",
    "\n",
    "# 获取 'status' 和 'sensor' 列\n",
    "# 删除包含错误值的行\n",
    "df = df[df['sensor'] != 'sensor']\n",
    "df['sensor'] = pd.to_numeric(df['sensor'])\n",
    "sensor_column = df['sensor'].astype(float)\n",
    "status_column = df['status'].astype(float)\n",
    "\n",
    "# 将 'status' 列中所有1变成0, 所有0.5变成-0.1\n",
    "status_column[status_column == 1] = 0\n",
    "status_column[status_column == 0.5] = -0.1\n",
    "\n",
    "# 将处理后的 'status' 列和 'sensor' 列相加，并将结果赋值给 'sensor' 列\n",
    "df['sensor'] = status_column + sensor_column\n",
    "\n",
    "# 输出结果\n",
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470374f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: segment dataset in sequence of activity\n",
      "STEP 3: segment dataset in sequence of activity\n",
      "[           date      time  sensor  status                                label\n",
      "876  2023/10/13  15:35:48     0.9     0.5  (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5),            date      time  sensor  status                                label\n",
      "878  2023/10/13  15:36:04     1.0     1.0  (0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5),            date      time  sensor  status                                label\n",
      "880  2023/10/13  15:36:10     2.0     1.0  (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "881  2023/10/13  15:36:11     3.0     1.0  (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "882  2023/10/13  15:36:12     0.9     0.5  (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "883  2023/10/13  15:36:12    61.0     1.0  (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5),            date      time  sensor  status                                label\n",
      "885  2023/10/13  15:36:14     1.9     0.5  (1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5)\n",
      "886  2023/10/13  15:36:14    60.9     0.5  (1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5)\n",
      "887  2023/10/13  15:36:15    11.0     1.0  (1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5)\n",
      "888  2023/10/13  15:36:16     2.9     0.5  (1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5)]\n",
      "STEP 4: transform sequences of activity in sentences\n",
      "['1.0', '2.0 3.0 61.0 0.9', '60.9 1.9 2.9 11.0 10.9', '11.0', '3.0 61.0 2.0 60.9', '10.9 27.0 22.0 2.9 21.0 1.9 24.0 23.0 25.0 26.9 20.9 24.9', '25.0', '21.9 22.0 24.9 21.9 25.0', '23.9 24.9 22.9 24.0 25.0 22.0 23.0 21.0 27.0', '24.9 21.9 61.0 22.9 20.9 3.0 62.0 26.9 2.9 63.0 64.0 60.9 61.9 62.0']\n",
      "[(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5), (0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5), (0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5)]\n",
      "STEP 5: sentences indexization\n",
      "[[1.0], [2.0, 3.0, 61.0, 0.9], [60.9, 1.9, 2.9, 11.0, 10.9], [11.0], [3.0, 61.0, 2.0, 60.9]]\n",
      "STEP 6: split indexed sentences in sliding windows\n",
      "[[1.0], [2.0, 3.0, 61.0, 0.9], [60.9, 1.9, 2.9, 11.0, 10.9], [11.0], [3.0, 61.0, 2.0, 60.9], [10.9, 27.0, 22.0, 2.9, 21.0, 1.9, 24.0, 23.0], [27.0, 22.0, 2.9, 21.0, 1.9, 24.0, 23.0, 25.0], [22.0, 2.9, 21.0, 1.9, 24.0, 23.0, 25.0, 26.9], [2.9, 21.0, 1.9, 24.0, 23.0, 25.0, 26.9, 20.9], [21.0, 1.9, 24.0, 23.0, 25.0, 26.9, 20.9, 24.9]]\n",
      "[(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), (1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5), (1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5)]\n",
      "STEP 7: pad sliding windows\n",
      "[[ 1.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 2.   3.  61.   0.9  0.   0.   0.   0. ]\n",
      " [60.9  1.9  2.9 11.  10.9  0.   0.   0. ]\n",
      " [11.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 3.  61.   2.  60.9  0.   0.   0.   0. ]\n",
      " [10.9 27.  22.   2.9 21.   1.9 24.  23. ]\n",
      " [27.  22.   2.9 21.   1.9 24.  23.  25. ]\n",
      " [22.   2.9 21.   1.9 24.  23.  25.  26.9]\n",
      " [ 2.9 21.   1.9 24.  23.  25.  26.9 20.9]\n",
      " [21.   1.9 24.  23.  25.  26.9 20.9 24.9]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0]\n",
      " [0 1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [1 1 1 1 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "328\n",
      "STEP 8: save sliding windows and labels\n"
     ]
    }
   ],
   "source": [
    "#  Segment dataset in sequence of activity ##\n",
    "print(\"STEP 1: segment dataset in sequence of activity\")\n",
    "\n",
    "#  Segment dataset in sequence of activity ##\n",
    "print(\"STEP 3: segment dataset in sequence of activity\")\n",
    "activity_sequences = segment_activities(df)\n",
    "print(activity_sequences[121:125])\n",
    "\n",
    "#  Transform sequences of activity in sentences ##\n",
    "print(\"STEP 4: transform sequences of activity in sentences\")\n",
    "sentences, label_sentences = sequences_to_sentences(activity_sequences)\n",
    "print(sentences[:10])\n",
    "print(label_sentences[:10])\n",
    "\n",
    "#  Indexization ##\n",
    "print(\"STEP 5: sentences indexization\")\n",
    "# 转换文本为整数序列\n",
    "sequences = [list(map(float, s.split())) for s in sentences]\n",
    "#sequences = [np.array(seq) for seq in sentences]\n",
    "\n",
    "print(sequences[:5])\n",
    "\n",
    "#  Split in sliding windows ##\n",
    "print(\"STEP 6: split indexed sentences in sliding windows\")\n",
    "X_windowed = []\n",
    "Y_windowed = []\n",
    "X_windowed_sen = []\n",
    "Y_windowed_sen = []\n",
    "win_size = 8\n",
    "step = 1\n",
    "for i, s in enumerate(sequences):\n",
    "    chunks = sliding_window(s, win_size, step)\n",
    "    for chunk in chunks:\n",
    "        X_windowed.append(chunk)\n",
    "        Y_windowed.append(label_sentences[i])\n",
    "print(X_windowed[0:10])\n",
    "print(Y_windowed[0:10])\n",
    "\n",
    "#  Pad windows ##\n",
    "print(\"STEP 7: pad sliding windows\")\n",
    "#padded_windows = pad_sequences(X_windowed, padding ='post', value=0.0)\n",
    "\n",
    "# 获取最大序列长度\n",
    "max_length = max(len(seq) for seq in X_windowed)\n",
    "\n",
    "# 使用 np.pad 函数填充每个序列\n",
    "padded_windows = [np.pad(seq, (0, max_length - len(seq)), mode='constant', constant_values=0.0) for seq in X_windowed]\n",
    "\n",
    "# 将结果转换为 NumPy 数组\n",
    "padded_windows = np.array(padded_windows)\n",
    "\n",
    "Y_windowed = np.array(Y_windowed)\n",
    "Y_windowed = Y_windowed.astype(int)\n",
    "print(padded_windows[:10])\n",
    "print(Y_windowed[:10])\n",
    "print(type(Y_windowed))\n",
    "print(len(Y_windowed))\n",
    "#  Save files ##\n",
    "print(\"STEP 8: save sliding windows and labels\")\n",
    "# np.save(\"{}_{}_padded_x_step1_state_linyu.npy\".format(r'/Users/zehaokou/Desktop/Technion/AI/plot/Linyu_dataset/', win_size), padded_windows)\n",
    "# np.save(\"label_sentences.npy\".format(r'/Users/zehaokou/Desktop/Technion/AI/plot/Linyu_dataset', win_size), Y_windowed)\n",
    "# pickle_file_path = '/Users/zehaokou/Desktop/Technion/AI/plot/Linyu_dataset/indexed_sentences.pkl'\n",
    "# with open(pickle_file_path, 'wb') as pickle_file:\n",
    "#     pickle.dump(indexed_sentences, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c6d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个空的图像数据列表和标签列表\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(padded_windows)):\n",
    "    \n",
    "    label = Y_windowed[i]\n",
    "#    label = label.astype(str)\n",
    "    label = np.array2string(label, precision=2, separator=',', suppress_small=True)\n",
    "    labels.append(label)\n",
    "    \n",
    "label_encoder = LabelEncoder()\n",
    "int_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f3a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['[0,0,0,0,0,0,0]' '[1,0,0,0,0,0,0]' '[1,1,1,0,0,0,0]' '[0,1,1,0,0,0,0]'\n",
      " '[1,1,1,0,0,0,0]' '[1,1,1,1,0,0,0]' '[1,1,1,1,0,0,0]' '[1,1,1,1,0,0,0]'\n",
      " '[1,1,1,1,0,0,0]' '[1,1,1,1,0,0,0]']\n",
      "[]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "{0: '[0,0,0,0,0,0,0]', 1: '[0,0,0,0,0,0,1]', 2: '[0,0,0,0,0,1,0]', 3: '[0,0,0,0,1,0,0]', 4: '[0,0,0,0,1,0,1]', 5: '[0,0,0,0,1,1,0]', 6: '[0,0,0,1,0,0,0]', 7: '[0,0,0,1,1,0,0]', 8: '[0,1,1,0,0,0,0]', 9: '[0,1,1,1,0,0,0]', 10: '[1,0,0,0,0,0,0]', 11: '[1,0,0,1,0,0,0]', 12: '[1,0,1,0,0,0,0]', 13: '[1,0,1,1,0,0,0]', 14: '[1,1,1,0,0,0,0]', 15: '[1,1,1,1,0,0,0]'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(padded_windows)):\n",
    "    \n",
    "    label = int_labels[i]\n",
    "    label = label.astype(str)\n",
    "    label = np.array2string(label, precision=2, separator=',', suppress_small=True)\n",
    "    \n",
    "#    label_dir = f\"/Users/zehaokou/Desktop/Technion/AI/plot/Linyu_dataset/1013/plot_train_state_7/{label}\"\n",
    "#    label_dir = f\"/Users/zehaokou/Desktop/Technion/AI/plot/Linyu_dataset/1013/plot_train_state_8\"\n",
    "    \n",
    "    zero = np.zeros((100,100))\n",
    "    for j in range(6):\n",
    "        index = 99 - padded_windows[i][j]\n",
    "        if index != 0:\n",
    "            if index - index.astype(int) != 0:\n",
    "                index = index.astype(int)\n",
    "                zero[index][2*j:(2*j+1)] = 0.5\n",
    "            elif index - index.astype(int) == 0:\n",
    "                index = index.astype(int)\n",
    "                zero[index][2*j:(2*j+1)] = 1\n",
    "            else:\n",
    "                zero[index][2*j:(2*j+1)] = 0\n",
    "\n",
    "#############填充状态s    \n",
    "    for row in range(100):\n",
    "        # 找到当前纵坐标下所有值不为0的点的横坐标\n",
    "        cols_with_value = [col for col in range(100) if zero[row][col] > 0]\n",
    "\n",
    "        if len(cols_with_value) > 0:\n",
    "            # 如果第一个值是0.5，从y=0向这一点连线\n",
    "            if zero[row][cols_with_value[0]] == 0.5:\n",
    "                zero[row][0:cols_with_value[0]] = 1\n",
    "\n",
    "            # 对相邻的on和off之间进行填充\n",
    "            for k in range(0, len(cols_with_value) - 1):\n",
    "                # If the current point is 'on' and the next point is 'off', fill between them\n",
    "                if zero[row][cols_with_value[k]] == 1 and zero[row][cols_with_value[k + 1]] == 0.5:\n",
    "                    zero[row][cols_with_value[k]:cols_with_value[k + 1]] = 1\n",
    "\n",
    "            # 如果最后一个值为1，从这点向y=not_nan_count*2 - 1连线\n",
    "            if zero[row][cols_with_value[-1]] == 1:\n",
    "                zero[row][cols_with_value[-1]:2*win_size-1] = 1\n",
    "\n",
    "    for row in range(100):\n",
    "# 找到当前纵坐标下所有值为1的点的横坐标\n",
    "        cols_with_value = [col for col in range(100) if zero[row][col] == 1]\n",
    "\n",
    "        # 将除了值为1的点外的其他点设置为0\n",
    "        zero[row, :] = 0\n",
    "        for col in cols_with_value:\n",
    "            zero[row, col] = 1\n",
    "        ###########\n",
    "\n",
    "    # 将zero数组的值乘以255\n",
    "    data = zero * 255\n",
    "    # 将data数组的数据类型转换为'uint8'\n",
    "    data = data.astype('uint8')\n",
    "    # 确保保存图像的目录存在，如果不存在就创建\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "    \n",
    "    # 生成图片文件的完整路径，这里使用一个计数器以防止覆盖同一标签下的不同图片\n",
    "#    img_path = os.path.join(label_dir, f\"{label}_{i}.png\")\n",
    "    img_path = os.path.join(label_dir, f\"{label}_{i}.png\")\n",
    "    \n",
    "    # 将图像数据保存为图片\n",
    "    img = Image.fromarray(data)\n",
    "    img.save(img_path)\n",
    "    \n",
    "    # 重置zero数组为224x224的零数组，为下一次迭代做准备\n",
    "    zero = np.zeros((100, 100))\n",
    "\n",
    "\n",
    "print('done')\n",
    "print(labels[:10])\n",
    "print(image_data[:10])\n",
    "#labels = labels.cpu().numpy()\n",
    "labels = np.array(labels)\n",
    "print(type(labels))\n",
    "print(type(image_data))\n",
    "\n",
    "#labels = np.array(labels)\n",
    "label_encoder = LabelEncoder()\n",
    "int_labels = label_encoder.fit_transform(labels)\n",
    "mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "open with \n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377207b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 16\n"
     ]
    }
   ],
   "source": [
    "# 使用方式\n",
    "# 使用 str.rsplit 分隔字符串，并保留前面的部分\n",
    "path, _ = label_dir.rsplit('/', 1)\n",
    "\n",
    "number_of_directories = count_directories(path)\n",
    "print(f'Number of directories: {number_of_directories}')\n",
    "\n",
    "# 指定数据集路径和类别数量\n",
    "\n",
    "dataset_path = path\n",
    "num_classes = number_of_directories\n",
    "\n",
    "# 获取每个类别的路径和图像文件名列表\n",
    "class_paths = []\n",
    "for i in range(num_classes):\n",
    "    \n",
    "    class_path = os.path.join(dataset_path, \"{}\".format(i))\n",
    "    class_files = os.listdir(class_path)\n",
    "#    print(class_files[:10])\n",
    "    class_paths.append((class_path, class_files))\n",
    "\n",
    "# 打乱每个类别的图像列表\n",
    "for class_path, class_files in class_paths:\n",
    "    random.shuffle(class_files)\n",
    "\n",
    "# 将数据集分成训练集和测试集\n",
    "train_file = open(dataset_path + \"/train.txt\", \"w\")\n",
    "test_file = open(dataset_path + \"/test.txt\", \"w\")\n",
    "for i, (class_path, class_files) in enumerate(class_paths):\n",
    "    num_train = int(len(class_files) * 0.7)\n",
    "    for j, filename in enumerate(class_files):\n",
    "        if j < num_train:\n",
    "            train_file.write(\"{} {}\\n\".format(os.path.join(class_path, filename), i))\n",
    "        else:\n",
    "            test_file.write(\"{} {}\\n\".format(os.path.join(class_path, filename), i))\n",
    "train_file.close()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d198ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查是否有可用的CUDA设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "## resnet\n",
    "#net = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "net = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "net.to(device)  # 将模型移动到CUDA设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003baf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载成功！\n",
      "FOLD 1/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 8.2205\n",
      "------------------------------ \n",
      " epoch 1\n",
      "Validation Loss: 5.5026\n",
      "------------------------------ \n",
      " epoch 2\n",
      "Validation Loss: 5.7288\n",
      "------------------------------ \n",
      " epoch 3\n",
      "Validation Loss: 4.5431\n",
      "------------------------------ \n",
      " epoch 4\n",
      "Validation Loss: 3.6435\n",
      "------------------------------ \n",
      " epoch 5\n",
      "Validation Loss: 3.1282\n",
      "------------------------------ \n",
      " epoch 6\n",
      "Validation Loss: 2.3626\n",
      "------------------------------ \n",
      " epoch 7\n",
      "Validation Loss: 2.1920\n",
      "------------------------------ \n",
      " epoch 8\n",
      "Validation Loss: 1.6341\n",
      "------------------------------ \n",
      " epoch 9\n",
      "Validation Loss: 1.0181\n",
      "------------------------------ \n",
      " epoch 10\n",
      "Validation Loss: 0.6406\n",
      "------------------------------ \n",
      " epoch 11\n",
      "Validation Loss: 0.5284\n",
      "------------------------------ \n",
      " epoch 12\n",
      "Validation Loss: 0.4616\n",
      "------------------------------ \n",
      " epoch 13\n",
      "Validation Loss: 0.3198\n",
      "------------------------------ \n",
      " epoch 14\n",
      "Validation Loss: 0.4058\n",
      "------------------------------ \n",
      " epoch 15\n",
      "Validation Loss: 0.1770\n",
      "------------------------------ \n",
      " epoch 16\n",
      "Validation Loss: 0.5383\n",
      "------------------------------ \n",
      " epoch 17\n",
      "Validation Loss: 0.3869\n",
      "------------------------------ \n",
      " epoch 18\n",
      "Validation Loss: 0.4582\n",
      "------------------------------ \n",
      " epoch 19\n",
      "Validation Loss: 0.2431\n",
      "------------------------------ \n",
      " epoch 20\n",
      "Validation Loss: 0.4444\n",
      "------------------------------ \n",
      " epoch 21\n",
      "Validation Loss: 0.4954\n",
      "------------------------------ \n",
      " epoch 22\n",
      "Validation Loss: 0.4431\n",
      "------------------------------ \n",
      " epoch 23\n",
      "Validation Loss: 0.3858\n",
      "------------------------------ \n",
      " epoch 24\n",
      "Validation Loss: 0.3926\n",
      "------------------------------ \n",
      " epoch 25\n",
      "Validation Loss: 0.3589\n",
      "------------------------------ \n",
      " epoch 26\n",
      "Validation Loss: 0.3344\n",
      "------------------------------ \n",
      " epoch 27\n",
      "Validation Loss: 0.3824\n",
      "------------------------------ \n",
      " epoch 28\n",
      "Validation Loss: 0.4077\n",
      "------------------------------ \n",
      " epoch 29\n",
      "Validation Loss: 0.3301\n",
      "------------------------------ \n",
      " epoch 30\n",
      "Validation Loss: 0.3536\n",
      "------------------------------ \n",
      " epoch 31\n",
      "Validation Loss: 0.4181\n",
      "------------------------------ \n",
      " epoch 32\n",
      "Validation Loss: 0.4483\n",
      "------------------------------ \n",
      " epoch 33\n",
      "Validation Loss: 0.5378\n",
      "------------------------------ \n",
      " epoch 34\n",
      "Validation Loss: 0.5172\n",
      "------------------------------ \n",
      " epoch 35\n",
      "Validation Loss: 0.4873\n",
      "------------------------------ \n",
      " epoch 36\n",
      "Validation Loss: 0.4289\n",
      "------------------------------ \n",
      " epoch 37\n",
      "Validation Loss: 0.4131\n",
      "------------------------------ \n",
      " epoch 38\n",
      "Validation Loss: 0.4762\n",
      "------------------------------ \n",
      " epoch 39\n",
      "Validation Loss: 0.4662\n",
      "------------------------------ \n",
      " epoch 40\n",
      "Validation Loss: 0.4795\n",
      "------------------------------ \n",
      " epoch 41\n",
      "Validation Loss: 0.4988\n",
      "------------------------------ \n",
      " epoch 42\n",
      "Validation Loss: 0.5873\n",
      "------------------------------ \n",
      " epoch 43\n",
      "Validation Loss: 0.6342\n",
      "------------------------------ \n",
      " epoch 44\n",
      "Validation Loss: 0.6640\n",
      "------------------------------ \n",
      " epoch 45\n",
      "Validation Loss: 0.7158\n",
      "------------------------------ \n",
      " epoch 46\n",
      "Validation Loss: 0.7720\n",
      "------------------------------ \n",
      " epoch 47\n",
      "Validation Loss: 0.7405\n",
      "------------------------------ \n",
      " epoch 48\n",
      "Validation Loss: 0.8857\n",
      "------------------------------ \n",
      " epoch 49\n",
      "Validation Loss: 0.9289\n",
      "------------------------------ \n",
      " epoch 50\n",
      "Validation Loss: 0.9281\n",
      "------------------------------ \n",
      " epoch 51\n",
      "Validation Loss: 0.9329\n",
      "------------------------------ \n",
      " epoch 52\n",
      "Validation Loss: 0.9435\n",
      "------------------------------ \n",
      " epoch 53\n",
      "Validation Loss: 0.9665\n",
      "------------------------------ \n",
      " epoch 54\n",
      "Validation Loss: 0.8604\n",
      "------------------------------ \n",
      " epoch 55\n",
      "Validation Loss: 0.5638\n",
      "------------------------------ \n",
      " epoch 56\n",
      "Validation Loss: 0.3067\n",
      "------------------------------ \n",
      " epoch 57\n",
      "Validation Loss: 0.6579\n",
      "------------------------------ \n",
      " epoch 58\n",
      "Validation Loss: 0.8800\n",
      "------------------------------ \n",
      " epoch 59\n",
      "Validation Loss: 0.5937\n",
      "------------------------------ \n",
      " epoch 60\n",
      "Validation Loss: 0.2777\n",
      "------------------------------ \n",
      " epoch 61\n",
      "Validation Loss: 0.3268\n",
      "------------------------------ \n",
      " epoch 62\n",
      "Validation Loss: 0.2533\n",
      "------------------------------ \n",
      " epoch 63\n",
      "Validation Loss: 0.3222\n",
      "------------------------------ \n",
      " epoch 64\n",
      "Validation Loss: 0.3409\n",
      "------------------------------ \n",
      " epoch 65\n",
      "Validation Loss: 0.3316\n",
      "Early stopping!\n",
      "FOLD 2/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0723\n",
      "------------------------------ \n",
      " epoch 1\n",
      "Validation Loss: 0.1985\n",
      "------------------------------ \n",
      " epoch 2\n",
      "Validation Loss: 0.2210\n",
      "------------------------------ \n",
      " epoch 3\n",
      "Validation Loss: 0.1274\n",
      "------------------------------ \n",
      " epoch 4\n",
      "Validation Loss: 0.3065\n",
      "------------------------------ \n",
      " epoch 5\n",
      "Validation Loss: 0.1176\n",
      "------------------------------ \n",
      " epoch 6\n",
      "Validation Loss: 0.0921\n",
      "------------------------------ \n",
      " epoch 7\n",
      "Validation Loss: 0.0915\n",
      "------------------------------ \n",
      " epoch 8\n",
      "Validation Loss: 0.0960\n",
      "------------------------------ \n",
      " epoch 9\n",
      "Validation Loss: 0.0865\n",
      "------------------------------ \n",
      " epoch 10\n",
      "Validation Loss: 0.0901\n",
      "------------------------------ \n",
      " epoch 11\n",
      "Validation Loss: 0.0867\n",
      "------------------------------ \n",
      " epoch 12\n",
      "Validation Loss: 0.0848\n",
      "------------------------------ \n",
      " epoch 13\n",
      "Validation Loss: 0.0793\n",
      "------------------------------ \n",
      " epoch 14\n",
      "Validation Loss: 0.0806\n",
      "------------------------------ \n",
      " epoch 15\n",
      "Validation Loss: 0.1379\n",
      "------------------------------ \n",
      " epoch 16\n",
      "Validation Loss: 0.4022\n",
      "------------------------------ \n",
      " epoch 17\n",
      "Validation Loss: 0.2289\n",
      "------------------------------ \n",
      " epoch 18\n",
      "Validation Loss: 0.1536\n",
      "------------------------------ \n",
      " epoch 19\n",
      "Validation Loss: 0.1333\n",
      "------------------------------ \n",
      " epoch 20\n",
      "Validation Loss: 0.1257\n",
      "------------------------------ \n",
      " epoch 21\n",
      "Validation Loss: 0.1213\n",
      "------------------------------ \n",
      " epoch 22\n",
      "Validation Loss: 0.3458\n",
      "------------------------------ \n",
      " epoch 23\n",
      "Validation Loss: 0.3745\n",
      "------------------------------ \n",
      " epoch 24\n",
      "Validation Loss: 0.4013\n",
      "------------------------------ \n",
      " epoch 25\n",
      "Validation Loss: 0.2179\n",
      "------------------------------ \n",
      " epoch 26\n",
      "Validation Loss: 0.2873\n",
      "------------------------------ \n",
      " epoch 27\n",
      "Validation Loss: 0.9525\n",
      "------------------------------ \n",
      " epoch 28\n",
      "Validation Loss: 0.5602\n",
      "------------------------------ \n",
      " epoch 29\n",
      "Validation Loss: 0.2040\n",
      "------------------------------ \n",
      " epoch 30\n",
      "Validation Loss: 0.1714\n",
      "------------------------------ \n",
      " epoch 31\n",
      "Validation Loss: 0.2476\n",
      "------------------------------ \n",
      " epoch 32\n",
      "Validation Loss: 0.6055\n",
      "------------------------------ \n",
      " epoch 33\n",
      "Validation Loss: 0.4728\n",
      "------------------------------ \n",
      " epoch 34\n",
      "Validation Loss: 0.4576\n",
      "------------------------------ \n",
      " epoch 35\n",
      "Validation Loss: 0.3857\n",
      "------------------------------ \n",
      " epoch 36\n",
      "Validation Loss: 0.3160\n",
      "------------------------------ \n",
      " epoch 37\n",
      "Validation Loss: 0.2771\n",
      "------------------------------ \n",
      " epoch 38\n",
      "Validation Loss: 0.2725\n",
      "------------------------------ \n",
      " epoch 39\n",
      "Validation Loss: 0.2704\n",
      "------------------------------ \n",
      " epoch 40\n",
      "Validation Loss: 0.2752\n",
      "------------------------------ \n",
      " epoch 41\n",
      "Validation Loss: 0.2897\n",
      "------------------------------ \n",
      " epoch 42\n",
      "Validation Loss: 0.3089\n",
      "------------------------------ \n",
      " epoch 43\n",
      "Validation Loss: 0.2794\n",
      "------------------------------ \n",
      " epoch 44\n",
      "Validation Loss: 0.3192\n",
      "------------------------------ \n",
      " epoch 45\n",
      "Validation Loss: 0.3134\n",
      "------------------------------ \n",
      " epoch 46\n",
      "Validation Loss: 0.2513\n",
      "------------------------------ \n",
      " epoch 47\n",
      "Validation Loss: 0.2470\n",
      "------------------------------ \n",
      " epoch 48\n",
      "Validation Loss: 0.2055\n",
      "------------------------------ \n",
      " epoch 49\n",
      "Validation Loss: 0.2110\n",
      "------------------------------ \n",
      " epoch 50\n",
      "Validation Loss: 0.2127\n",
      "Early stopping!\n",
      "FOLD 3/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0008\n",
      "------------------------------ \n",
      " epoch 1\n",
      "Validation Loss: 0.0010\n",
      "------------------------------ \n",
      " epoch 2\n",
      "Validation Loss: 0.0011\n",
      "------------------------------ \n",
      " epoch 3\n",
      "Validation Loss: 0.0009\n",
      "------------------------------ \n",
      " epoch 4\n",
      "Validation Loss: 0.0041\n",
      "------------------------------ \n",
      " epoch 5\n",
      "Validation Loss: 0.0023\n",
      "------------------------------ \n",
      " epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0023\n",
      "------------------------------ \n",
      " epoch 7\n",
      "Validation Loss: 0.0021\n",
      "------------------------------ \n",
      " epoch 8\n",
      "Validation Loss: 0.0023\n",
      "------------------------------ \n",
      " epoch 9\n",
      "Validation Loss: 0.0015\n",
      "------------------------------ \n",
      " epoch 10\n",
      "Validation Loss: 0.0015\n",
      "------------------------------ \n",
      " epoch 11\n",
      "Validation Loss: 0.0032\n",
      "------------------------------ \n",
      " epoch 12\n",
      "Validation Loss: 0.0041\n",
      "------------------------------ \n",
      " epoch 13\n",
      "Validation Loss: 0.0042\n",
      "------------------------------ \n",
      " epoch 14\n",
      "Validation Loss: 0.0039\n",
      "------------------------------ \n",
      " epoch 15\n",
      "Validation Loss: 0.0039\n",
      "------------------------------ \n",
      " epoch 16\n",
      "Validation Loss: 0.0035\n",
      "------------------------------ \n",
      " epoch 17\n",
      "Validation Loss: 0.0039\n",
      "------------------------------ \n",
      " epoch 18\n",
      "Validation Loss: 0.0040\n",
      "------------------------------ \n",
      " epoch 19\n",
      "Validation Loss: 0.0032\n",
      "------------------------------ \n",
      " epoch 20\n",
      "Validation Loss: 0.0057\n",
      "------------------------------ \n",
      " epoch 21\n",
      "Validation Loss: 0.0086\n",
      "------------------------------ \n",
      " epoch 22\n",
      "Validation Loss: 0.0125\n",
      "------------------------------ \n",
      " epoch 23\n",
      "Validation Loss: 0.0108\n",
      "------------------------------ \n",
      " epoch 24\n",
      "Validation Loss: 0.0051\n",
      "------------------------------ \n",
      " epoch 25\n",
      "Validation Loss: 0.0032\n",
      "------------------------------ \n",
      " epoch 26\n",
      "Validation Loss: 0.0033\n",
      "------------------------------ \n",
      " epoch 27\n",
      "Validation Loss: 0.0037\n",
      "------------------------------ \n",
      " epoch 28\n",
      "Validation Loss: 0.0035\n",
      "------------------------------ \n",
      " epoch 29\n",
      "Validation Loss: 0.0040\n",
      "------------------------------ \n",
      " epoch 30\n",
      "Validation Loss: 0.0038\n",
      "------------------------------ \n",
      " epoch 31\n",
      "Validation Loss: 0.0041\n",
      "------------------------------ \n",
      " epoch 32\n",
      "Validation Loss: 0.0046\n",
      "------------------------------ \n",
      " epoch 33\n",
      "Validation Loss: 0.0042\n",
      "------------------------------ \n",
      " epoch 34\n",
      "Validation Loss: 0.0049\n",
      "------------------------------ \n",
      " epoch 35\n",
      "Validation Loss: 0.0033\n",
      "------------------------------ \n",
      " epoch 36\n",
      "Validation Loss: 0.0065\n",
      "------------------------------ \n",
      " epoch 37\n",
      "Validation Loss: 0.0127\n",
      "------------------------------ \n",
      " epoch 38\n",
      "Validation Loss: 0.0079\n",
      "------------------------------ \n",
      " epoch 39\n",
      "Validation Loss: 0.0043\n",
      "------------------------------ \n",
      " epoch 40\n",
      "Validation Loss: 0.0073\n",
      "------------------------------ \n",
      " epoch 41\n",
      "Validation Loss: 0.0291\n",
      "------------------------------ \n",
      " epoch 42\n",
      "Validation Loss: 0.0647\n",
      "------------------------------ \n",
      " epoch 43\n",
      "Validation Loss: 0.0780\n",
      "------------------------------ \n",
      " epoch 44\n",
      "Validation Loss: 0.0594\n",
      "------------------------------ \n",
      " epoch 45\n",
      "Validation Loss: 0.0773\n",
      "------------------------------ \n",
      " epoch 46\n",
      "Validation Loss: 0.0715\n",
      "------------------------------ \n",
      " epoch 47\n",
      "Validation Loss: 0.0534\n",
      "------------------------------ \n",
      " epoch 48\n",
      "Validation Loss: 0.0412\n",
      "------------------------------ \n",
      " epoch 49\n",
      "Validation Loss: 0.0301\n",
      "------------------------------ \n",
      " epoch 50\n",
      "Validation Loss: 0.0676\n",
      "Early stopping!\n",
      "FOLD 4/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0652\n",
      "Early stopping!\n",
      "FOLD 5/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.1180\n",
      "Early stopping!\n",
      "FOLD 6/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 1\n",
      "Validation Loss: 0.0003\n",
      "------------------------------ \n",
      " epoch 2\n",
      "Validation Loss: 0.0007\n",
      "------------------------------ \n",
      " epoch 3\n",
      "Validation Loss: 0.0012\n",
      "------------------------------ \n",
      " epoch 4\n",
      "Validation Loss: 0.6631\n",
      "------------------------------ \n",
      " epoch 5\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 6\n",
      "Validation Loss: 0.0006\n",
      "------------------------------ \n",
      " epoch 7\n",
      "Validation Loss: 0.0009\n",
      "------------------------------ \n",
      " epoch 8\n",
      "Validation Loss: 0.0011\n",
      "------------------------------ \n",
      " epoch 9\n",
      "Validation Loss: 0.0014\n",
      "------------------------------ \n",
      " epoch 10\n",
      "Validation Loss: 0.0014\n",
      "------------------------------ \n",
      " epoch 11\n",
      "Validation Loss: 0.0009\n",
      "------------------------------ \n",
      " epoch 12\n",
      "Validation Loss: 0.0010\n",
      "------------------------------ \n",
      " epoch 13\n",
      "Validation Loss: 0.0009\n",
      "------------------------------ \n",
      " epoch 14\n",
      "Validation Loss: 0.0007\n",
      "------------------------------ \n",
      " epoch 15\n",
      "Validation Loss: 0.0006\n",
      "------------------------------ \n",
      " epoch 16\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 17\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 18\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 19\n",
      "Validation Loss: 0.0016\n",
      "------------------------------ \n",
      " epoch 20\n",
      "Validation Loss: 0.0043\n",
      "------------------------------ \n",
      " epoch 21\n",
      "Validation Loss: 0.0054\n",
      "------------------------------ \n",
      " epoch 22\n",
      "Validation Loss: 0.0047\n",
      "------------------------------ \n",
      " epoch 23\n",
      "Validation Loss: 0.0033\n",
      "------------------------------ \n",
      " epoch 24\n",
      "Validation Loss: 0.0026\n",
      "------------------------------ \n",
      " epoch 25\n",
      "Validation Loss: 0.0019\n",
      "------------------------------ \n",
      " epoch 26\n",
      "Validation Loss: 0.0049\n",
      "------------------------------ \n",
      " epoch 27\n",
      "Validation Loss: 0.0041\n",
      "------------------------------ \n",
      " epoch 28\n",
      "Validation Loss: 0.0053\n",
      "------------------------------ \n",
      " epoch 29\n",
      "Validation Loss: 0.0035\n",
      "------------------------------ \n",
      " epoch 30\n",
      "Validation Loss: 0.0006\n",
      "------------------------------ \n",
      " epoch 31\n",
      "Validation Loss: 0.0007\n",
      "------------------------------ \n",
      " epoch 32\n",
      "Validation Loss: 0.0006\n",
      "------------------------------ \n",
      " epoch 33\n",
      "Validation Loss: 0.0004\n",
      "------------------------------ \n",
      " epoch 34\n",
      "Validation Loss: 0.0003\n",
      "------------------------------ \n",
      " epoch 35\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 36\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 37\n",
      "Validation Loss: 0.0006\n",
      "------------------------------ \n",
      " epoch 38\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 39\n",
      "Validation Loss: 0.0007\n",
      "------------------------------ \n",
      " epoch 40\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 41\n",
      "Validation Loss: 0.0005\n",
      "------------------------------ \n",
      " epoch 42\n",
      "Validation Loss: 0.0004\n",
      "------------------------------ \n",
      " epoch 43\n",
      "Validation Loss: 0.0004\n",
      "------------------------------ \n",
      " epoch 44\n",
      "Validation Loss: 0.0009\n",
      "------------------------------ \n",
      " epoch 45\n",
      "Validation Loss: 0.0020\n",
      "------------------------------ \n",
      " epoch 46\n",
      "Validation Loss: 0.0016\n",
      "------------------------------ \n",
      " epoch 47\n",
      "Validation Loss: 0.0012\n",
      "------------------------------ \n",
      " epoch 48\n",
      "Validation Loss: 0.0012\n",
      "------------------------------ \n",
      " epoch 49\n",
      "Validation Loss: 0.0015\n",
      "------------------------------ \n",
      " epoch 50\n",
      "Validation Loss: 0.0023\n",
      "------------------------------ \n",
      " epoch 51\n",
      "Validation Loss: 0.0025\n",
      "Early stopping!\n",
      "FOLD 7/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.1466\n",
      "Early stopping!\n",
      "FOLD 8/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0007\n",
      "Early stopping!\n",
      "FOLD 9/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.1662\n",
      "Early stopping!\n",
      "FOLD 10/10\n",
      "------------------------------ \n",
      " epoch 0\n",
      "Validation Loss: 0.0559\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 自定义图片图片读取方式\n",
    "def MyLoader(path):\n",
    "    return Image.open(path).convert('L')\n",
    "\n",
    "# def MyLoader(path):\n",
    "#     return np.load(path, allow_pickle=True)\n",
    "    \n",
    "    \n",
    "class MyDataset (Dataset):\n",
    "    # 构造函数设置默认参数\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=MyLoader):\n",
    "        with open(txt, 'r') as fh:\n",
    "            imgs = []\n",
    "            for line in fh:\n",
    "                line = line.strip('\\n')  # 移除字符串首尾的换行符\n",
    "                line = line.rstrip()  # 删除末尾空\n",
    "                words = line.split( )  # 以空格为分隔符 将字符串分成\n",
    "                imgs.append((words[0], int(words[1]))) # imgs中包含有图像路径和标签\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        #调用定义的loader方法\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "\n",
    "root = path + '/'\n",
    "train_data = MyDataset(txt=root + 'train.txt', transform=transforms.ToTensor())\n",
    "test_data = MyDataset(txt=root + 'test.txt', transform=transforms.ToTensor())\n",
    "\n",
    "test_num = len(test_data)\n",
    "\n",
    "#train_data 和test_data包含多有的训练与测试数据，调用DataLoader批量加载\n",
    "trainloader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print('加载成功！')\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "\n",
    "# CrossEntropyLoss就是我们需要的损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Parameters\n",
    "patience = 50  # for early stopping\n",
    "n_folds = 10   # for k-fold cross-validation\n",
    "num_epochs = 200\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "# kfold = KFold(n_splits=n_folds, shuffle=True, random_state=5)\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
    "early_stop_counter = 0\n",
    "best_loss = float('inf')\n",
    "best_model_wts = None\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainloader.dataset)):\n",
    "    print(f\"FOLD {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    # Define your network and optimizer here, they should be re-initialized for each fold\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "    \n",
    "    \n",
    "    trainloader_fold = torch.utils.data.DataLoader(trainloader.dataset, batch_size=32, sampler=train_subsampler)\n",
    "    valloader_fold = torch.utils.data.DataLoader(trainloader.dataset, batch_size=32, sampler=val_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*30, '\\n','epoch', epoch)\n",
    "        net.train()\n",
    "        loss100 = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader_fold):\n",
    "            # Training code remains largely the same...\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # 注意需要复制到GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss100 += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader_fold):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(valloader_fold)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_model_wts = net.state_dict().copy()  # 更新最佳模型的权重\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "# 保存最佳模型的权重到文件\n",
    "model_save_path = path +'/' +'best_model.pth'\n",
    "torch.save(best_model_wts, model_save_path)\n",
    "# Finally, you could report the average performance across all folds.\n",
    "#plt.plot(train_accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274d508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 73.333333 %\n",
      "Loss : 3.031840 %\n",
      "Balanced Accuracy : 47.410714 %\n",
      "[[ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  1  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  1  2  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  1  1  0  2  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 28  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  1 11  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  2  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "predicted_list = []\n",
    "labels_list = []\n",
    "# 构造测试的dataloader\n",
    "dataiter = iter(testloader)\n",
    "# 预测正确的数量和总数量\n",
    "correct = 0\n",
    "total = 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 预测\n",
    "        outputs = net(images)\n",
    "        # 输出概率分布，最大概率的一项作为预测分类\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # 将预测结果和真实结果添加到列表中\n",
    "        predicted_list.extend(predicted.cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "confusion_mat = confusion_matrix(labels_list, predicted_list)\n",
    "print('Accuracy : %f %%' % (\n",
    "    100 * correct / test_num))\n",
    "print('Loss : %f %%' % (\n",
    "    loss.item()))\n",
    "balanced_accuracy = balanced_accuracy_score(labels_list, predicted_list, adjusted=False)\n",
    "print('Balanced Accuracy : %f %%' %(100 * balanced_accuracy))\n",
    "print(confusion_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
