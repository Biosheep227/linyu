{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2655bb8c",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cbaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的CUDA设备,这是针对mac的NPU,如果是英伟达的显卡则把mps改为cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "## resnet18\n",
    "# net = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "net = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "net.to(device)  # 将模型移动到CUDA设备上\n",
    "print(next(net.parameters()).device)  # 打印模型的设备信息\n",
    "\n",
    "# 自定义图片图片读取方式，可以自行增加resize、数据增强等操作\n",
    "def MyLoader(path):\n",
    "#    return Image.open(path)\n",
    "#     return Image.open(path).convert('RGB')\n",
    "    return np.load(path)\n",
    "    \n",
    "class MyDataset (Dataset):\n",
    "    # 构造函数设置默认参数\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=MyLoader):\n",
    "        with open(txt, 'r') as fh:\n",
    "            imgs = []\n",
    "            for line in fh:\n",
    "                line = line.strip('\\n')  # 移除字符串首尾的换行符\n",
    "                line = line.rstrip()  # 删除末尾空\n",
    "                words = line.split( )  # 以空格为分隔符 将字符串分成\n",
    "                imgs.append((words[0], int(words[1]))) # imgs中包含有图像路径和标签\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        #调用定义的loader方法\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "root = r\"/images/\"\n",
    "train_data = MyDataset(txt=root + 'train.txt', transform=transforms.ToTensor())\n",
    "test_data = MyDataset(txt=root + 'test.txt', transform=transforms.ToTensor())\n",
    "\n",
    "test_num = len(test_data)\n",
    "\n",
    "trainloader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print('加载成功！')\n",
    "\n",
    "# CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Parameters\n",
    "patience = 30  # for early stopping\n",
    "n_folds = 3   # for k-fold cross-validation\n",
    "num_epochs = 100\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "# kfold = KFold(n_splits=n_folds, shuffle=True, random_state=5)\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
    "early_stop_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(trainloader.dataset)):\n",
    "    print(f\"FOLD {fold + 1}/{n_folds}\")\n",
    "    \n",
    "    # Define your network and optimizer here, they should be re-initialized for each fold\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "    \n",
    "    \n",
    "    trainloader_fold = torch.utils.data.DataLoader(trainloader.dataset, batch_size=32, sampler=train_subsampler)\n",
    "    valloader_fold = torch.utils.data.DataLoader(trainloader.dataset, batch_size=32, sampler=val_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*30, '\\n','epoch', epoch)\n",
    "        net.train()\n",
    "        loss100 = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader_fold):\n",
    "            # Training code remains largely the same...\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # 注意需要复制到GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss100 += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader_fold):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(valloader_fold)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# Finally, you could report the average performance across all folds.\n",
    "#plt.plot(train_accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c59fe5",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c03fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "labels_list = []\n",
    "# 构造测试的dataloader\n",
    "dataiter = iter(testloader)\n",
    "# 预测正确的数量和总数量\n",
    "correct = 0\n",
    "total = 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 预测\n",
    "        outputs = net(images)\n",
    "        # 输出概率分布，最大概率的一项作为预测分类\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # 将预测结果和真实结果添加到列表中\n",
    "        predicted_list.extend(predicted.cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "confusion_mat = confusion_matrix(labels_list, predicted_list)\n",
    "print('Accuracy : %f %%' % (\n",
    "    100 * correct / test_num))\n",
    "print('Loss : %f %%' % (\n",
    "    loss.item()))\n",
    "balanced_accuracy = balanced_accuracy_score(labels_list, predicted_list, adjusted=False)\n",
    "print('Balanced Accuracy : %f %%' %(100 * balanced_accuracy))\n",
    "print(confusion_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
